# -*- coding: utf-8 -*-
"""richter-s-prediction-of-earthquake-damage1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VcWtP57BmkbkN_XAsYMCAkBC4NCRGki7
"""

# # This Python 3 environment comes with many helpful analytics libraries installed
# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# # For example, here's several helpful packages to load

# import numpy as np # linear algebra
# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# # Input data files are available in the read-only "../input/" directory
# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

# import os
# for dirname, _, filenames in os.walk('/kaggle/input'):
#     for filename in filenames:
#         print(os.path.join(dirname, filename))


# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import warnings
from sklearn.metrics import fbeta_score, make_scorer
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import make_pipeline
from pylab import rcParams
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import hamming_loss
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import plot_precision_recall_curve
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import classification_report
from sklearn import metrics
from sklearn.metrics import jaccard_score
from sklearn.metrics import log_loss
from sklearn.metrics import matthews_corrcoef
from sklearn.metrics import zero_one_loss
from sklearn.metrics import brier_score_loss
from sklearn.metrics import balanced_accuracy_score

df = pd.read_csv("train_values.csv")



df.head()

df.columns

"""> #  Description
* > geo_level_1_id, geo_level_2_id, geo_level_3_id (type: int): geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.
* > count_floors_pre_eq (type: int): number of floors in the building before the earthquake.
* > age (type: int): age of the building in years.
* > area_percentage (type: int): normalized area of the building footprint.
* > height_percentage (type: int): normalized height of the building footprint.
* > land_surface_condition (type: categorical): surface condition of the land where the building was built. Possible values: n, o, t.
* > foundation_type (type: categorical): type of foundation used while building. Possible values: h, i, r, u, w.
* > roof_type (type: categorical): type of roof used while building. Possible values: n, q, x.
* > ground_floor_type (type: categorical): type of the ground floor. Possible values: f, m, v, x, z.
* > other_floor_type (type: categorical): type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.
* > position (type: categorical): position of the building. Possible values: j, o, s, t.
* > plan_configuration (type: categorical): building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.
* > has_superstructure_adobe_mud (type: binary): flag variable that indicates if the superstructure was made of Adobe/Mud.
* > has_superstructure_mud_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Stone.
*  > has_superstructure_stone_flag (type: binary): flag variable that indicates if the superstructure was made of Stone.
*   > has_superstructure_cement_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Stone.
*   > has_superstructure_mud_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Brick.
*   > has_superstructure_cement_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Brick.
*   > has_superstructure_timber (type: binary): flag variable that indicates if the superstructure was made of Timber.
*   > has_superstructure_bamboo (type: binary): flag variable that indicates if the superstructure was made of Bamboo.
*   > has_superstructure_rc_non_engineered (type: binary): flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.
*   > has_superstructure_rc_engineered (type: binary): flag variable that indicates if the superstructure was made of engineered reinforced concrete.
*   > has_superstructure_other (type: binary): flag variable that indicates if the superstructure was made of any other material.
*   > legal_ownership_status (type: categorical): legal ownership status of the land where building was built. Possible values: a, r, v, w.
*   > count_families (type: int): number of families that live in the building.
*   > has_secondary_use (type: binary): flag variable that indicates if the building was used for any secondary purpose.
*   > has_secondary_use_agriculture (type: binary): flag variable that indicates if the building was used for agricultural purposes.
*   > has_secondary_use_hotel (type: binary): flag variable that indicates if the building was used as a hotel.
*   > has_secondary_use_rental (type: binary): flag variable that indicates if the building was used for rental purposes.
*   > has_secondary_use_institution (type: binary): flag variable that indicates if the building was used as a location of any institution.
*   > has_secondary_use_school (type: binary): flag variable that indicates if the building was used as a school.
*   > has_secondary_use_industry (type: binary): flag variable that indicates if the building was used for industrial purposes.
*   > has_secondary_use_health_post (type: binary): flag variable that indicates if the building was used as a health post.
*   > has_secondary_use_gov_office (type: binary): flag variable that indicates if the building was used fas a government office.
*   > has_secondary_use_use_police (type: binary): flag variable that indicates if the building was used as a police station.
*   > has_secondary_use_other (type: binary): flag variable that indicates if the building was secondarily used for other purposes.
"""

df.shape

df2 = pd.read_csv("train_labels.csv")

df2.head()

df2.shape

# df['damage_grade'] = df2['damage_grade']
df.head()

# plt.figure(figsize=(10,10))
# cor=df.corr()["damage_grade"]
# cor=pd.DataFrame(cor)
# sns.heatmap(cor,annot=True,cmap="viridis")

# exploring the statstical fearures of train dataset.
df.describe().T.style.background_gradient(cmap='Set2',low =0.4,high=0.1,axis=0)

df.describe(include="object").T.style.background_gradient(cmap='Set2',axis=0)

# checking the types of varibles in the dataset(int,float,object)
dtypes=pd.DataFrame(df.dtypes,columns=["Data Type"])
dtypes["Unique Values"]=df.nunique()
dtypes["Null Values"]=df.isnull().sum()
dtypes["% null Values"]=df.isnull().sum()/len(df)
dtypes.style.background_gradient(cmap='Set2',axis=0)

"""> We're trying to predict the ordinal variable damage_grade, which represents a level of damage to the building that was hit by the earthquake. There are 3 grades of the damage
> 
1. > 1: represents low damage
2. > 2: represents a medium amount of damage
3. > 3:
represents almost complete destruction
"""

df2[df2['damage_grade']==1] = "Low_Damage"
df2[df2['damage_grade']==2] = "Medium_Damage"
df2[df2['damage_grade']==3] = "High_Damage"

y = df2['damage_grade']
y

y.unique()

y.value_counts()

df.isna().any()

df.info()

df.head()

df["has_secondary_use_hotel"].unique()
df["has_secondary_use_other"].unique()

col = df.columns
col = df[['has_superstructure_adobe_mud',
       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',
       'has_superstructure_cement_mortar_stone',
       'has_superstructure_mud_mortar_brick',
       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',
       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',
       'has_superstructure_rc_engineered', 'has_superstructure_other',
       'legal_ownership_status', 'has_secondary_use',
       'has_secondary_use_agriculture', 'has_secondary_use_hotel',
       'has_secondary_use_rental', 'has_secondary_use_institution',
       'has_secondary_use_school', 'has_secondary_use_industry',
       'has_secondary_use_health_post', 'has_secondary_use_gov_office',
       'has_secondary_use_use_police', 'has_secondary_use_other']]

for i in col:
    print (df[i].unique())

df[['has_superstructure_adobe_mud',
       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',
       'has_superstructure_cement_mortar_stone',
       'has_superstructure_mud_mortar_brick',
       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',
       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',
       'has_superstructure_rc_engineered', 'has_superstructure_other',
       'legal_ownership_status', 'has_secondary_use',
       'has_secondary_use_agriculture', 'has_secondary_use_hotel',
       'has_secondary_use_rental', 'has_secondary_use_institution',
       'has_secondary_use_school', 'has_secondary_use_industry',
       'has_secondary_use_health_post', 'has_secondary_use_gov_office',
       'has_secondary_use_use_police', 'has_secondary_use_other']] = df[['has_superstructure_adobe_mud',
       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',
       'has_superstructure_cement_mortar_stone',
       'has_superstructure_mud_mortar_brick',
       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',
       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',
       'has_superstructure_rc_engineered', 'has_superstructure_other',
       'legal_ownership_status', 'has_secondary_use',
       'has_secondary_use_agriculture', 'has_secondary_use_hotel',
       'has_secondary_use_rental', 'has_secondary_use_institution',
       'has_secondary_use_school', 'has_secondary_use_industry',
       'has_secondary_use_health_post', 'has_secondary_use_gov_office',
       'has_secondary_use_use_police', 'has_secondary_use_other']].astype('object')

df.info()

l0 = df['building_id'].unique()
l1 = df['geo_level_1_id'].unique()
l2 = df['geo_level_2_id'].unique()
l3 = df['geo_level_3_id'].unique()

len(l1)
len(l2)
len(l3)
len(l0)#all unique

df1 = df[['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',
       'land_surface_condition', 'foundation_type', 'roof_type',
       'ground_floor_type', 'other_floor_type', 'position',
       'plan_configuration', 'has_superstructure_adobe_mud',
       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',
       'has_superstructure_cement_mortar_stone',
       'has_superstructure_mud_mortar_brick',
       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',
       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',
       'has_superstructure_rc_engineered', 'has_superstructure_other',
       'legal_ownership_status', 'count_families', 'has_secondary_use',
       'has_secondary_use_agriculture', 'has_secondary_use_hotel',
       'has_secondary_use_rental', 'has_secondary_use_institution',
       'has_secondary_use_school', 'has_secondary_use_industry',
       'has_secondary_use_health_post', 'has_secondary_use_gov_office',
       'has_secondary_use_use_police', 'has_secondary_use_other']]

df1.info()

df3 = pd.read_csv("test_values.csv")
df4 = pd.DataFrame()
df4 = df3[['count_floors_pre_eq', 'age', 'area_percentage', 'height_percentage',
       'land_surface_condition', 'foundation_type', 'roof_type',
       'ground_floor_type', 'other_floor_type', 'position',
       'plan_configuration', 'has_superstructure_adobe_mud',
       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',
       'has_superstructure_cement_mortar_stone',
       'has_superstructure_mud_mortar_brick',
       'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',
       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',
       'has_superstructure_rc_engineered', 'has_superstructure_other',
       'legal_ownership_status', 'count_families', 'has_secondary_use',
       'has_secondary_use_agriculture', 'has_secondary_use_hotel',
       'has_secondary_use_rental', 'has_secondary_use_institution',
       'has_secondary_use_school', 'has_secondary_use_industry',
       'has_secondary_use_health_post', 'has_secondary_use_gov_office',
       'has_secondary_use_use_police', 'has_secondary_use_other']]

df.shape

df4.shape

X1 = pd.DataFrame(df1)
X1=X1.append(df4)
X1.shape

X1 = pd.get_dummies(X1,drop_first=True)

"""> # GENERATE MODEL REPORT"""

def generate_model_report(y_actual, y_predicted):
    print("Accuracy = " , accuracy_score(y_actual, y_predicted))
    print("Precision = " ,precision_score(y_actual, y_predicted,average="micro"))
    print("Recall = " ,recall_score(y_actual, y_predicted,average="micro"))
    print("F1 Score = " ,f1_score(y_actual, y_predicted,average="micro"))
    print("Cohen Kappa score= ",cohen_kappa_score(y_actual,y_predicted))
    print("Hamming Loss = ",hamming_loss(y_actual,y_predicted))
    print("Jaccard Score = ",jaccard_score(y_actual, y_predicted,average="micro"))
#     print("Log Loss = ",log_loss(y_actual, y_predicted))
    print("Matthews correlation coefficient = ", matthews_corrcoef(y_actual, y_predicted))
    print("Zero one loss = ",zero_one_loss(y_actual, y_predicted))
#     print("brier_score_loss  = ",brier_score_loss(y_actual, y_predicted))
    print("Balanced accuracy = ",balanced_accuracy_score(y_actual, y_predicted))

"""> # Generate auc roc curve"""

def generate_auc_roc_curve(clf, X_test):
    y_pred_proba = clf.predict_proba(X_test)[:, 1]
    fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    plt.plot(fpr,tpr,label="AUC ROC Curve with Area Under the curve ="+str(auc))
    plt.legend(loc=4)
    plt.show()
    pass

"""> # Normalization"""

from sklearn import preprocessing
# from sklearn.preprocessing import Normalizer
X1 = preprocessing.normalize(X1, norm='l2')

X1.shape

df3.shape

df.shape

test = X1[260601:]
test.shape

X = X1[:260601]
X.shape

y.shape

"""> # Train test split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.10, random_state = 0)

y_train
len(X_train)

"""> # Generate auc_roc_curve"""

def generate_auc_roc_curve(clf, X_test):
    y_pred_proba = clf.predict_proba(X_test)[:, 1]
    fpr, tpr, thresholds = roc_curve(y_test,  y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba,multi_class = "ovr",average = "macro")
    plt.plot(fpr,tpr,label="AUC ROC Curve with Area Under the curve ="+str(auc))
    plt.legend(loc=4)
    plt.show()
    pass

"""> # LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import GridSearchCV
grid={"C":np.logspace(-3,0,3,5,7),"max_iter":[100,200,300,400,500],"solver":[ "saga"]}# l1 lasso l2 ridge
lr1 = LogisticRegression()
grid_cv=GridSearchCV(lr1,grid,cv=10,verbose=0)
grid_cv.fit(X_train,y_train)
params = grid_cv.best_params_
lr1.set_params(**params)
lr1.fit(X_train,y_train)
y_lr1 = lr1.predict(X_test)

params

lr1.score(X_train,y_train)

lr1.score(X_test,y_test)

generate_model_report(y_test,y_lr1)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_lr1, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(lr1, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(random_state = 0, multi_class = "multinomial", solver="newton-cg",C=1000)
lr.get_params()

lr.fit(X_train,y_train)

y_lr = lr.predict(X_test)

generate_model_report(y_test, y_lr)

y_prob = lr.predict_proba(X_test)
y_prob

lr.score(X_train,y_train)
#It meand very low bias which means underfitting.

lr.score(X_test,y_test)

macro_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class="ovo",
                                  average="macro")
weighted_roc_auc_ovo = roc_auc_score(y_test, y_prob, multi_class="ovo",
                                     average="weighted")
macro_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class="ovr",
                                  average="macro")
weighted_roc_auc_ovr = roc_auc_score(y_test, y_prob, multi_class="ovr",
                                     average="weighted")
print("One-vs-One ROC AUC scores:\n{:.6f} (macro),\n{:.6f} "
      "(weighted by prevalence)"
      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))
print("One-vs-Rest ROC AUC scores:\n{:.6f} (macro),\n{:.6f} "
      "(weighted by prevalence)"
      .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))



from yellowbrick.classifier.rocauc import roc_auc
roc_auc(lr, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

f1_score(y_test,y_lr,average = "micro")

f1_score(y_test,y_lr,average = "macro")

f1_score(y_test,y_lr,average = "weighted")

from sklearn.metrics import classification_report
print(classification_report(y_test, y_lr, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

from sklearn.metrics import confusion_matrix
confusion_matrix(y_test, y_lr, labels=['Low_Damage', 'Medium_Damage', 'High_Damage'])

"""# > **KNN**"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=25, weights = 'distance')
knn.fit(X_train,y_train)

y_knn = knn.predict(X_test)

generate_model_report(y_test,y_knn)

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(knn, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

from sklearn.metrics import classification_report
print(classification_report(y_test, y_knn, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

f1_score(y_test,y_knn,average = "micro")

f1_score(y_test,y_knn,average = "macro")

f1_score(y_test,y_knn,average = "weighted")

y_knn_prob = knn.predict_proba(X_test)
# brier_score_loss(y_test,y_knn_prob[:,1])

y_knn_prob

y

scoring = make_scorer(f1_score, average = 'micro')

from sklearn.model_selection import GridSearchCV
parameters={'weights':['distance','uniform'], 'n_neighbors':[3,5,7,9,12,15,20,25]}
kn = GridSearchCV(knn, parameters,scoring=scoring, cv=5)
kn.fit(X_train,y_train)
params = kn.best_params_
kn_grid = KNeighborsClassifier()
kn_grid.set_params(**params)
kn_grid.fit(X_train,y_train)
y_grid = kn_grid.predict(X_test)

params

generate_model_report(y_test,y_grid)

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(kn_grid, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

from sklearn.metrics import classification_report
print(classification_report(y_test, y_grid, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

"""# > **Naive Bayes**"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train,y_train)

y_nb = nb.predict(X_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_nb, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(kn_grid, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

generate_model_report(y_test,y_nb)





"""#> **SVM**"""

from sklearn import svm
svm = svm.SVC(C=1000)

svm.get_params

svm.fit(X_train,y_train)
y_svm = svm.predict(X_test)

svm.score(X_train,y_train)

svm.score(X_test,y_test)

generate_model_report(y_test,y_svm)

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(svm, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

# from sklearn.model_selection import GridSearchCV
# parameters={"C":[1,10,100,500,1000],'gamma':['auto','scale']}
# sv = GridSearchCV(svm, parameters,scoring= 'f1',
#  cv=5)
# sv.fit(X_train,y_train)
# params = sv.best_params_
# svm2 = svm.SVC()
# svm2.set_params(**params)
# svm2.fit(X_train,y_train)
# y_grid = svm2.predict(X_test)

# generate_model_report(y_test,y_grid)

from yellowbrick.classifier.rocauc import roc_auc
# roc_auc(svm2, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

"""# > **Decision Tree**"""

from sklearn.tree import DecisionTreeClassifier
tree1 = DecisionTreeClassifier(class_weight="balanced")

tree1.get_params

tree1.fit(X_train,y_train)

y_t1 = tree1.predict(X_test)

tree1.score(X_train,y_train)

tree1.score(X_test,y_test)
#POOR Performance

from sklearn.metrics import confusion_matrix 
cm = confusion_matrix(y_test, y_t1) 
cm

generate_model_report(y_test,y_t1)

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(tree1, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

#class weight balanced didn't improve it!

from sklearn.model_selection import permutation_test_score
score, permutation_scores, pvalue = permutation_test_score(
    tree1, X_train, y_train, scoring="accuracy", cv=5, n_permutations=20, n_jobs=1)
print("Classification score %s (pvalue : %s)" % (score, pvalue))

scoring = make_scorer(f1_score, average = 'micro')

from yellowbrick.model_selection import LearningCurve
visualizer = LearningCurve(
    tree1, cv=10, scoring=scoring,verbose = 0
)

visualizer.fit(X_train, y_train)        # Fit the data to the visualizer
visualizer.show()

"""# > **Random Forest**"""

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(oob_score = True,n_estimators=250)

clf.get_params

clf.fit(X_train,y_train)
y_clf = clf.predict(X_test)

clf.score(X_test,y_test)

clf.score(X_train,y_train)

generate_model_report(y_test,y_clf)

clf.oob_score_

from yellowbrick.classifier.rocauc import roc_auc
roc_auc(clf, X_train, y_train, X_test=X_test, y_test=y_test, classes=["Low_damage","Medium_damage","High_damage"])

# from sklearn.model_selection import permutation_test_score
# score, permutation_scores, pvalue = permutation_test_score(
#     clf, X_train, y_train, scoring="accuracy", cv=2, n_permutations=10, n_jobs=1)
# print("Classification score %s (pvalue : %s)" % (score, pvalue))

scoring = make_scorer(f1_score,average='micro')

from yellowbrick.model_selection import LearningCurve
visualizer = LearningCurve( clf, cv=10, scoring=scoring,verbose = 0 ) 
visualizer.fit(X_train, y_train)        # Fit the data to the visualizer 
visualizer.show()

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(clf, X_test, y_test)  # doctest: +SKIP
plt.show()  # doctest: +SKIP

from sklearn.metrics import classification_report
print(classification_report(y_test, y_clf, labels=['Low_Damage', 'Medium_Damage', 'High_Damage']))

y



"""# > **XGBOOST CLASSIFIER**"""

from xgboost import XGBClassifier
xgb = XGBClassifier(tree_method = 'hist', min_child_weight = 3, n_estimators =250 , learning_rate=0.05,max_depth=15, reg_lambda=0, class_weight="balanced",num_parallel_tree=3,grow_policy = "lossguide" )

# parameters = {'learning_rate': [0.05,0.1,0.3], #so called `eta` value
#               'max_depth': [10,15,20],
#               'min_child_weight': [1,5],              
          
#               'n_estimators': [150,200,250,300],
#                }

# from sklearn.utils import class_weight
# class_weights = list(class_weight.compute_class_weight('balanced',
#                                              np.unique(y_train),
#                                              y_train))

# w_array = np.ones(y_train.shape[0], dtype = 'float')
# for i, val in enumerate(y_train):
#     w_array[i] = class_weights[val-1]

# xgb.fit(X_train, y_train, sample_weight=w_array)


# sample_weight=compute_sample_weight("balanced", y)



xgb.fit(X_train,y_train)

y_xgb = xgb.predict(X_test)

xgb.score(X_test,y_test)

xgb.score(X_train,y_train)

generate_model_report(y_test,y_xgb)

from sklearn.metrics import plot_confusion_matrix
plot_confusion_matrix(xgb, X_test, y_test)  # doctest: +SKIP
plt.show()  # doctest: +SKIP

f1_score(y_test,y_xgb,average="micro")























df3.head()

y_ans = xgb.predict(test)

df5 = pd.DataFrame()
df5['building_id'] = df3['building_id']

df5['damage_grade'] = y_ans
df5

df5[df5['damage_grade']=="Low_Damage"]=1
df5[df5['damage_grade']=="Medium_Damage"]=2
df5[df5['damage_grade']=="High_Damage"]=3
df5['building_id'] = df3['building_id']

df5

df5.index = df5['building_id']

df5

df5 = df5.drop(columns = 'building_id')

df5

df5.to_csv("submit2.csv")

